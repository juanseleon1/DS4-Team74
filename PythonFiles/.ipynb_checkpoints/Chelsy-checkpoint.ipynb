{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modificacion de Tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tablas que tenemos son:\n",
    "1. Activos: Informacion de cada activo\n",
    "2. Historico Adjuntos Activos OT: Match de que activo corresponde a que .txt, e informacion de la orden de trabajo fuera del reporte\n",
    "3. Registros ordenes de Trabajo: Informacion de ordenes de trabajo, incluidas los reportes en formato html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import prettytable as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\USER\\\\OneDrive - Universidad Nacional de Colombia\\\\Documentos\\\\DS4A\\\\Proyecto Final\\\\Repoo\\\\Data\\\\Activos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a15c130e700a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactivos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\Activos.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\USER\\\\OneDrive - Universidad Nacional de Colombia\\\\Documentos\\\\DS4A\\\\Proyecto Final\\\\Repoo\\\\Data\\\\Activos.csv'"
     ]
    }
   ],
   "source": [
    "activos = pd.read_csv('/Data\\Activos.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ots = pd.read_csv(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\HistoricoAdjuntosActivosOT.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = pd.read_excel(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\RegistrosOrdenesDeTrabajo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pt.PrettyTable()\n",
    "cols.add_column('Activos', activos.columns.tolist())\n",
    "cols.add_column('Hist OTs', hist_ots.columns.tolist()+ [''])\n",
    "cols.add_column('OTs', ots.columns.tolist())\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregamos a la tabla de Historico de ordenes de trabajo el Reporte en texto libre correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificaciones al nombre de archivo para asegurar que sea como el del txt\n",
    "hist_ots['DOCUMENT'] = hist_ots['DOCUMENT'].replace('ISTORIA', 'istoria', regex = True)\n",
    "hist_ots['DOCUMENT'] = hist_ots['DOCUMENT'].apply(str.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una columna vacia por ahora\n",
    "hist_ots['WORKLOG'] = ''\n",
    "\n",
    "for i in range(len(hist_ots.DOCUMENT)):\n",
    "    filename = hist_ots.DOCUMENT[i]         # Leemos el nombre de archivo para cada una\n",
    "    \n",
    "    try:\n",
    "        lineas = []                             # Lista vacía para guardar el contenido\n",
    "        with open (fr'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\HISTORICOS_OT\\{filename}.txt', 'rt') as worklog:  # Abre el .txt\n",
    "            for linea in worklog:               # Lee linea por linea\n",
    "                lineas.append(linea)            # Guarda la linea como elemento de la lista\n",
    "        \n",
    "        worklog = ''.join(lineas)               # Juntamos en un string\n",
    "\n",
    "        hist_ots.WORKLOG[i] = worklog           # Asignamos el worklog a la entrada correspondiente\n",
    "\n",
    "    except:\n",
    "        i =+ 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos los caracteres \\n (new line) con espacios\n",
    "hist_ots['WORKLOG'] = hist_ots['WORKLOG'].replace('\\n', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos NA lo que quedo vacío\n",
    "vacio_a_na = {'': np.nan}\n",
    "hist_ots['WORKLOG'] = hist_ots['WORKLOG'].replace(vacio_a_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miramos la cantidad de vacios\n",
    "hist_ots.WORKLOG.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos con los vacios del repositorio, con una muestra random de la mitad:\n",
    "vacios = ['HistoriaJDE_OT_3815495.txt',\n",
    "          'HistoriaJDE_OT_3816996.txt',\n",
    "          'HistoriaJDE_OT_3818147.txt',\n",
    "          'HistoriaJDE_OT_3818153.txt',\n",
    "          'HistoriaJDE_OT_3821964.txt',\n",
    "          'HistoriaJDE_OT_3824321.txt',\n",
    "          'HistoriaJDE_OT_3824493.txt',\n",
    "          'HistoriaJDE_OT_3825889.txt',\n",
    "          'HistoriaJDE_OT_3826393.txt',\n",
    "          'HistoriaJDE_OT_3829275.txt',\n",
    "          'HistoriaJDE_OT_3832219.txt',\n",
    "          'HistoriaJDE_OT_3834917.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ots.loc[hist_ots.DOCUMENT.isin(vacios)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun el repositorio, hay 1301 vacios, que parece que no estaban en la tabla. Y parece que hay 9908 en la tabla que no coinciden con ningun .txt. \n",
    "\n",
    "(Total de archivos .txt - vacios) = (Total del filas del data frame - NaN en la columna de worklog)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#Obtenemos el total de los archivos\n",
    "files = os.listdir(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\HISTORICOS_OT')\n",
    "\n",
    "(len(files) - 1301) == (len(hist_ots.DOCUMENT) - 9908)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivos con info en la carpeta\n",
    "len(files) - 1301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivos con info en la tabla de viejos modificada\n",
    "len(hist_ots.DOCUMENT) - 9908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segun esto hay unos 5k .txt que no estan en la tabla? \n",
    "53065 - 48483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miramos los 9k que si estan pero no tienen .txt\n",
    "hist_ots.DOCUMENT.loc[hist_ots.WORKLOG.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes = hist_ots.DOCUMENT.loc[hist_ots.WORKLOG.isna()]\n",
    "\n",
    "good_docs = []\n",
    "for doc in faltantes:\n",
    "    if len(doc) < 27: good_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parece que solo se está saltando ese por x o y motivo, lo agregamos y ya\n",
    "hist_ots.WORKLOG.loc[hist_ots.DOCUMENT == 'HistoriaJDE_OT_3641553'] = 'Fecha: Noviembre 15/2017 Programo: Daniel Palacios O.Ejecuto: Jairo Torres y Frank Córdoba. Se realiza inspección y limpieza al barraje de salida, se realiza inspección y mantenimiento a mallas separadoras del barraje, baquelitas separadoras de barras, conexiones entre barras y estado del aislamiento, también se revisan el estado de los CTLs, de sus conexiones eléctricas en el tablero +CCCTS. Trabajo ejecutado por: Jairo Torres y Frank Córdoba. XE: LIMPIAR E INSPECCIONAR BARRAJE ESTATOR GENERADOR UNIDAD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viejos que están en la tabla pero no en los .txt\n",
    "hist_ots.WORKLOG.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los nombres de nuestros .txt son de 26 caracteres, miramos que no haya quedado ninguno de esos sin worklog en la tabla\n",
    "set(hist_ots.DOCUMENT.loc[hist_ots.WORKLOG.isna()].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora si, guardo el csv\n",
    "hist_ots.to_csv('historico_OTs_texto_libre.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quitamos las tag html de la tabla de Historico reciente de OTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots['WORKLOG'] = ots['WORKLOG'].apply(html2text.html2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos los caracteres \\n (new line) con espacios\n",
    "ots['WORKLOG'] = ots['WORKLOG'].replace('\\n', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de entradas en la tabla de nuevos\n",
    "len(ots.WORKLOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin info en la tabla de nuevos\n",
    "ots.WORKLOG.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el csv\n",
    "ots.to_csv('historico_OTs_recientes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla que relacione activo, fecha y reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viejos = hist_ots[['ASSETNUM','SLXNUMTOT','SLXFECINICIOOT','SLXFECFINOT','WORKLOG']]\n",
    "nuevos = ots[['ASSETNUM','WONUM','ACTSTART','ACTFINISH','WORKLOG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viejos['ANTIGUEDAD'] = 'Antiguo'\n",
    "nuevos['ANTIGUEDAD'] = 'Reciente'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viejos = viejos.rename(columns={'SLXNUMTOT': 'WONUM','SLXFECINICIOOT': 'ACTSTART','SLXFECFINOT':'ACTFINISH'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viejos.WORKLOG.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viejos['ACTSTART'] = pd.to_datetime(viejos['ACTSTART'])\n",
    "viejos['ACTFINISH'] = pd.to_datetime(viejos['ACTFINISH'])\n",
    "viejos['ASSETNUM'] = viejos['ASSETNUM'].astype('object')\n",
    "\n",
    "nuevos['ACTSTART'] = pd.to_datetime(nuevos['ACTSTART'])\n",
    "nuevos['ACTFINISH'] = pd.to_datetime(nuevos['ACTFINISH'])\n",
    "nuevos['ASSETNUM'] = nuevos['ASSETNUM'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = viejos.append(nuevos, ignore_index=True)\n",
    "todos = todos.sort_values(by = ['ASSETNUM', 'ACTSTART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos.isna().WORKLOG.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos.to_csv('relacion_ots_activo.csv', na_rep = 'Reporte No Disponible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activos = pd.read_csv(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\Activos.csv', delimiter=';')\n",
    "hist_ots = pd.read_csv(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\HistoricoAdjuntosActivosOT.csv', delimiter=';')\n",
    "ots = pd.read_excel(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\RegistrosOrdenesDeTrabajo.xlsx')\n",
    "todas_ots = pd.read_csv(r'C:\\Users\\USER\\OneDrive - Universidad Nacional de Colombia\\Documentos\\DS4A\\Proyecto Final\\Repoo\\Data\\DataSetsProcesados\\Relacion_ots_activo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = hist_ots.WORKTYPE)\n",
    "plt.title('OTs por tipo, regimen antiguo')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "sns.countplot(y = pd.DataFrame(hist_ots.ASSETNUM.value_counts()).ASSETNUM)\n",
    "plt.title('Incidencia Número de OTs por Activo, regimen antiguo')\n",
    "#plt.xticks(rotation = 90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_date = pd.DataFrame(hist_ots.SLXFECCREACIONOT.value_counts())\n",
    "by_date['date'] = by_date.index\n",
    "by_date['date'] = pd.to_datetime(by_date['date'])\n",
    "by_date.sort_values(by = 'date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 7))\n",
    "sns.barplot(y = 'SLXFECCREACIONOT', x = 'date', data = by_date)\n",
    "plt.title('Incidencia Creación de OTs por Fecha, regimen antiguo')\n",
    "plt.xticks(np.arange(4300, step = 100), rotation = 90)\n",
    "plt.ylim(0,400)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(x = ots.WORKTYPE)\n",
    "plt.title('OTs por tipo, regimen nuevo')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(y = ots.REMEDY)\n",
    "plt.title('OTs por arreglo, regimen nuevo')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_date = pd.DataFrame(ots.ACTSTART.value_counts())\n",
    "by_date['date'] = by_date.index\n",
    "by_date.sort_values(by = 'date', inplace = True)\n",
    "\n",
    "plt.figure(figsize = (20, 7))\n",
    "sns.barplot(y = 'ACTSTART', x = 'date', data = by_date)\n",
    "plt.title('Incidencia Creación de OTs por Fecha, regimen nuevo')\n",
    "plt.xticks(np.arange(13600, step = 150), rotation = 90)\n",
    "plt.ylim(0,10)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots.PROBLEM = ots.PROBLEM.astype(str)\n",
    "ots.PROBLEMS = ots.PROBLEM.apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_problems = []\n",
    "for i in range(len(ots.PROBLEMS)):\n",
    "\tall_problems.append(ots.PROBLEMS[i])\n",
    "all_problems_flat = [ item for elem in all_problems for item in elem]\n",
    "\n",
    "from collections import Counter\n",
    "dict = Counter(all_problems_flat)\n",
    "problems = pd.DataFrame.from_dict(dict, orient = 'index')\n",
    "problems.rename(columns = {0: 'Total'}, inplace = True)\n",
    "problems.drop(index='nan', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 40))\n",
    "sns.barplot(x = problems.Total, y = problems.index, data = problems)\n",
    "plt.title('Incidencia Problemas, regimen nuevo')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots.CAUSE = ots.CAUSE.astype(str)\n",
    "ots.CAUSES = ots.CAUSE.apply(lambda x: x.split(','))\n",
    "\n",
    "all_causes = []\n",
    "for i in range(len(ots.CAUSES)):\n",
    "\tall_causes.append(ots.CAUSES[i])\n",
    "all_causes_flat = [ item for elem in all_causes for item in elem]\n",
    "\n",
    "#from collections import Counter\n",
    "dict = Counter(all_causes_flat)\n",
    "causes = pd.DataFrame.from_dict(dict, orient = 'index')\n",
    "causes.rename(columns = {0: 'Total'}, inplace = True)\n",
    "causes.drop(index='nan', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 50))\n",
    "sns.barplot(x = causes.Total, y = causes.index, data = causes)\n",
    "plt.title('Incidencia Causas, regimen nuevo')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assets = pd.DataFrame(todos.ASSETNUM.value_counts())\n",
    "top100 = all_assets.iloc[:100].copy()\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.barplot(x = top100.index, y = top100.ASSETNUM, data=top100, order=top100.index)\n",
    "plt.title('Activos con muchos OTs')\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100assets = activos.loc[activos.ASSETNUM.isin(top100.index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100.rename(columns = {'ASSETNUM': 'TOTAL'}, inplace = True)\n",
    "top100['ASSETNUM'] = top100.index\n",
    "top100['ASSETNUM'] = top100.ASSETNUM.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100daños = top100.merge(right=top100assets, how = 'left', on = 'ASSETNUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTStop100 = pd.DataFrame(top100daños.groupby('DESCRIPTION').sum('TOTAL'))\n",
    "OTStop100['DESC'] = OTStop100.index\n",
    "OTStop100.sort_values(by='TOTAL', ascending=  False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.barplot(x = 'TOTAL', y= 'DESC', data = OTStop100.iloc[:20])\n",
    "plt.title('Assets with the most workorders')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y = todos.ANTIGUEDAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('spanish'))\n",
    "\n",
    "#Esto sirve para configurar NLTK. La primera vez puede tardar un poco\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = todos.loc[~(todos.WORKLOG.isna())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports['tokenized'] = reports.WORKLOG.apply(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reports.WORKLOG)):\n",
    "\treports.tokenized[i] = [word for word in reports.tokenized[i] if '1' not in word]\n",
    "\treports.tokenized[i] = [word for word in reports.tokenized[i] if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e55832998f3a8a26e2992baea321569607972aaacc4daf2de44a7713ecd8a64f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
